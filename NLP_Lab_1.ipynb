{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYN9ioyXABIZ",
        "outputId": "5b34affe-a6f5-4f1c-c690-6bf3bc5c34e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nbformat': 4,\n",
              " 'nbformat_minor': 0,\n",
              " 'metadata': {'colab': {'provenance': []},\n",
              "  'kernelspec': {'name': 'python3', 'display_name': 'Python 3'},\n",
              "  'language_info': {'name': 'python'}},\n",
              " 'cells': [{'cell_type': 'markdown',\n",
              "   'source': ['#Assignment 1 — NLP PIPELINE'],\n",
              "   'metadata': {'id': 'Zag3B4rpun_s'}},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['# Step 1:Install required libraries'],\n",
              "   'metadata': {'id': '0R1IPli-usMy'}},\n",
              "  {'cell_type': 'code',\n",
              "   'source': ['!pip install nltk scikit-learn pandas numpy\\n'],\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/', 'height': 0},\n",
              "    'id': 'wJ9TlEh1rsBn',\n",
              "    'outputId': 'f3f6eeec-ecab-40c4-fb98-4d8bd49bf4b6'},\n",
              "   'execution_count': 1,\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stdout',\n",
              "     'text': ['Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\\n',\n",
              "      'Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\\n',\n",
              "      'Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\\n',\n",
              "      'Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\\n',\n",
              "      'Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\\n',\n",
              "      'Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\\n',\n",
              "      'Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\\n',\n",
              "      'Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\\n',\n",
              "      'Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\\n',\n",
              "      'Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\\n',\n",
              "      'Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\\n',\n",
              "      'Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\\n',\n",
              "      'Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\\n',\n",
              "      'Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\\n']}]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['#Step 2:IMPORT LIBRARIES'],\n",
              "   'metadata': {'id': 'cgGA6POIsDo8'}},\n",
              "  {'cell_type': 'code',\n",
              "   'source': ['import nltk\\n',\n",
              "    'from nltk.tokenize import word_tokenize\\n',\n",
              "    'from nltk.corpus import stopwords\\n',\n",
              "    'from nltk.stem import PorterStemmer, WordNetLemmatizer\\n',\n",
              "    '\\n',\n",
              "    'import pandas as pd\\n',\n",
              "    'from sklearn.feature_extraction.text import TfidfVectorizer\\n',\n",
              "    'from sklearn.linear_model import LogisticRegression\\n',\n",
              "    'from sklearn.model_selection import train_test_split\\n',\n",
              "    'from sklearn.metrics import accuracy_score\\n',\n",
              "    '\\n',\n",
              "    \"nltk.download('punkt')\\n\",\n",
              "    \"nltk.download('stopwords')\\n\",\n",
              "    \"nltk.download('wordnet')\\n\"],\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/', 'height': 0},\n",
              "    'id': '5sDCewqusLLU',\n",
              "    'outputId': 'bafc7837-4904-4375-c005-f180c3788c63'},\n",
              "   'execution_count': 2,\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stderr',\n",
              "     'text': ['[nltk_data] Downloading package punkt to /root/nltk_data...\\n',\n",
              "      '[nltk_data]   Unzipping tokenizers/punkt.zip.\\n',\n",
              "      '[nltk_data] Downloading package stopwords to /root/nltk_data...\\n',\n",
              "      '[nltk_data]   Unzipping corpora/stopwords.zip.\\n',\n",
              "      '[nltk_data] Downloading package wordnet to /root/nltk_data...\\n']},\n",
              "    {'output_type': 'execute_result',\n",
              "     'data': {'text/plain': ['True']},\n",
              "     'metadata': {},\n",
              "     'execution_count': 2}]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['#STEP 3 — Enter a Custom Paragraph'],\n",
              "   'metadata': {'id': 'KeMj4V2Qsi8l'}},\n",
              "  {'cell_type': 'code',\n",
              "   'source': ['paragraph = \"\"\"\\n',\n",
              "    'NLP is an amazing field. It helps computers understand human language.\\n',\n",
              "    'We can perform tokenization, remove stopwords, and apply stemming and lemmatization.\\n',\n",
              "    'This helps in processing text for Machine Learning.\\n',\n",
              "    '\"\"\"\\n',\n",
              "    'print(\"Original Paragraph:\\\\n\", paragraph)\\n'],\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/', 'height': 0},\n",
              "    'id': 'xH7E79yQsl4I',\n",
              "    'outputId': '2a0accc8-c6ca-41b4-a13b-6c9a00a0a402'},\n",
              "   'execution_count': 3,\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stdout',\n",
              "     'text': ['Original Paragraph:\\n',\n",
              "      ' \\n',\n",
              "      'NLP is an amazing field. It helps computers understand human language.\\n',\n",
              "      'We can perform tokenization, remove stopwords, and apply stemming and lemmatization.\\n',\n",
              "      'This helps in processing text for Machine Learning.\\n',\n",
              "      '\\n']}]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['#STEP 4 — Tokenization'],\n",
              "   'metadata': {'id': 'Ox_ha_KlstPQ'}},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['Tokenization is the process of splitting a paragraph into individual words or tokens.\\n',\n",
              "    'It helps the computer understand text word-by-word.'],\n",
              "   'metadata': {'id': 'UWtZeufsuNbn'}},\n",
              "  {'cell_type': 'code',\n",
              "   'source': ['import nltk\\n',\n",
              "    '\\n',\n",
              "    \"nltk.download('punkt')\\n\",\n",
              "    \"nltk.download('punkt_tab')\\n\",\n",
              "    \"nltk.download('stopwords')\\n\",\n",
              "    \"nltk.download('wordnet')\\n\"],\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/', 'height': 0},\n",
              "    'id': '0FDBTMtstJY6',\n",
              "    'outputId': '7fb63c08-51b8-4769-8565-0f824b5d638a'},\n",
              "   'execution_count': 4,\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stderr',\n",
              "     'text': ['[nltk_data] Downloading package punkt to /root/nltk_data...\\n',\n",
              "      '[nltk_data]   Package punkt is already up-to-date!\\n',\n",
              "      '[nltk_data] Downloading package punkt_tab to /root/nltk_data...\\n',\n",
              "      '[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\\n',\n",
              "      '[nltk_data] Downloading package stopwords to /root/nltk_data...\\n',\n",
              "      '[nltk_data]   Package stopwords is already up-to-date!\\n',\n",
              "      '[nltk_data] Downloading package wordnet to /root/nltk_data...\\n',\n",
              "      '[nltk_data]   Package wordnet is already up-to-date!\\n']},\n",
              "    {'output_type': 'execute_result',\n",
              "     'data': {'text/plain': ['True']},\n",
              "     'metadata': {},\n",
              "     'execution_count': 4}]},\n",
              "  {'cell_type': 'code',\n",
              "   'source': ['tokens = word_tokenize(paragraph)\\n',\n",
              "    'print(\"\\\\n--- TOKENIZATION RESULT ---\\\\n\")\\n',\n",
              "    'print(tokens)\\n'],\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/', 'height': 0},\n",
              "    'id': '4neXW5eFsvMo',\n",
              "    'outputId': 'e37458b6-876d-47c3-b6f0-aecd2d26a8d0'},\n",
              "   'execution_count': 5,\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stdout',\n",
              "     'text': ['\\n',\n",
              "      '--- TOKENIZATION RESULT ---\\n',\n",
              "      '\\n',\n",
              "      \"['NLP', 'is', 'an', 'amazing', 'field', '.', 'It', 'helps', 'computers', 'understand', 'human', 'language', '.', 'We', 'can', 'perform', 'tokenization', ',', 'remove', 'stopwords', ',', 'and', 'apply', 'stemming', 'and', 'lemmatization', '.', 'This', 'helps', 'in', 'processing', 'text', 'for', 'Machine', 'Learning', '.']\\n\"]}]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['#STEP 5 — Stopword Removal'],\n",
              "   'metadata': {'id': 'ljbkGrY4tSCX'}},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['Stopwords are very common words like “the, is, am, are, of, in”.\\n',\n",
              "    'They don’t add meaning, so we remove them to keep only important words.'],\n",
              "   'metadata': {'id': '0YxOJxRKuTg8'}},\n",
              "  {'cell_type': 'code',\n",
              "   'source': [\"stop_words = set(stopwords.words('english'))\\n\",\n",
              "    '\\n',\n",
              "    'filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\\n',\n",
              "    '\\n',\n",
              "    'print(\"\\\\n--- AFTER STOPWORD REMOVAL ---\\\\n\")\\n',\n",
              "    'print(filtered_tokens)\\n'],\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/', 'height': 0},\n",
              "    'id': 'RrysGzVqtT37',\n",
              "    'outputId': '0fd04c61-0ff1-4147-b252-67a9fd9c6aa7'},\n",
              "   'execution_count': 6,\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stdout',\n",
              "     'text': ['\\n',\n",
              "      '--- AFTER STOPWORD REMOVAL ---\\n',\n",
              "      '\\n',\n",
              "      \"['NLP', 'amazing', 'field', '.', 'helps', 'computers', 'understand', 'human', 'language', '.', 'perform', 'tokenization', ',', 'remove', 'stopwords', ',', 'apply', 'stemming', 'lemmatization', '.', 'helps', 'processing', 'text', 'Machine', 'Learning', '.']\\n\"]}]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['#STEP 6 — Stemming'],\n",
              "   'metadata': {'id': 'WZLANtgvthYU'}},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['Stemming reduces words to a basic form by cutting the ends.\\n',\n",
              "    'Example:\\n',\n",
              "    '\\n',\n",
              "    '“playing” → “play”\\n',\n",
              "    '\\n',\n",
              "    '“studies” → “studi”\\n',\n",
              "    '\\n',\n",
              "    'It is fast but not always perfect.'],\n",
              "   'metadata': {'id': 'N89FPZDhuZdA'}},\n",
              "  {'cell_type': 'code',\n",
              "   'source': ['stemmer = PorterStemmer()\\n',\n",
              "    '\\n',\n",
              "    'stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\\n',\n",
              "    '\\n',\n",
              "    'print(\"\\\\n--- STEMMING RESULT ---\\\\n\")\\n',\n",
              "    'print(stemmed_words)\\n'],\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/', 'height': 0},\n",
              "    'id': 'lwY2E2v5tmS6',\n",
              "    'outputId': '3c516241-17b1-4724-f3c5-c1a64c9947ae'},\n",
              "   'execution_count': 7,\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stdout',\n",
              "     'text': ['\\n',\n",
              "      '--- STEMMING RESULT ---\\n',\n",
              "      '\\n',\n",
              "      \"['nlp', 'amaz', 'field', '.', 'help', 'comput', 'understand', 'human', 'languag', '.', 'perform', 'token', ',', 'remov', 'stopword', ',', 'appli', 'stem', 'lemmat', '.', 'help', 'process', 'text', 'machin', 'learn', '.']\\n\"]}]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['#STEP 7 — Lemmatization'],\n",
              "   'metadata': {'id': 'BLO1p4DZtskw'}},\n",
              "  {'cell_type': 'markdown',\n",
              "   'source': ['Lemmatization converts a word to its proper dictionary base form.\\n',\n",
              "    'Example:\\n',\n",
              "    '\\n',\n",
              "    '“better” → “good”\\n',\n",
              "    '\\n',\n",
              "    '“studies” → “study”\\n',\n",
              "    '\\n',\n",
              "    'It is more accurate than stemming because it uses vocabulary + grammar rules.'],\n",
              "   'metadata': {'id': 'Hlt5H9ZTue4F'}},\n",
              "  {'cell_type': 'code',\n",
              "   'source': ['lemmatizer = WordNetLemmatizer()\\n',\n",
              "    '\\n',\n",
              "    'lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\\n',\n",
              "    '\\n',\n",
              "    'print(\"\\\\n--- LEMMATIZATION RESULT ---\\\\n\")\\n',\n",
              "    'print(lemmatized_words)\\n'],\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/', 'height': 0},\n",
              "    'id': 'BcOkOyMGtxW7',\n",
              "    'outputId': '9ac74b37-95ad-4efa-efe6-a498e9a2ef21'},\n",
              "   'execution_count': 8,\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stdout',\n",
              "     'text': ['\\n',\n",
              "      '--- LEMMATIZATION RESULT ---\\n',\n",
              "      '\\n',\n",
              "      \"['NLP', 'amazing', 'field', '.', 'help', 'computer', 'understand', 'human', 'language', '.', 'perform', 'tokenization', ',', 'remove', 'stopwords', ',', 'apply', 'stemming', 'lemmatization', '.', 'help', 'processing', 'text', 'Machine', 'Learning', '.']\\n\"]}]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": []\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"#Assignment 1 — NLP PIPELINE\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"Zag3B4rpun_s\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"# Step 1:Install required libraries\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"0R1IPli-usMy\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"!pip install nltk scikit-learn pandas numpy\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 0\n",
        "        },\n",
        "        \"id\": \"wJ9TlEh1rsBn\",\n",
        "        \"outputId\": \"f3f6eeec-ecab-40c4-fb98-4d8bd49bf4b6\"\n",
        "      },\n",
        "      \"execution_count\": 1,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\\n\",\n",
        "            \"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\\n\",\n",
        "            \"Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\\n\",\n",
        "            \"Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\\n\",\n",
        "            \"Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\\n\",\n",
        "            \"Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\\n\",\n",
        "            \"Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\\n\",\n",
        "            \"Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\\n\",\n",
        "            \"Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\\n\",\n",
        "            \"Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\\n\",\n",
        "            \"Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\\n\",\n",
        "            \"Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\\n\",\n",
        "            \"Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\\n\",\n",
        "            \"Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"#Step 2:IMPORT LIBRARIES\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"cgGA6POIsDo8\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"import nltk\\n\",\n",
        "        \"from nltk.tokenize import word_tokenize\\n\",\n",
        "        \"from nltk.corpus import stopwords\\n\",\n",
        "        \"from nltk.stem import PorterStemmer, WordNetLemmatizer\\n\",\n",
        "        \"\\n\",\n",
        "        \"import pandas as pd\\n\",\n",
        "        \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\",\n",
        "        \"from sklearn.linear_model import LogisticRegression\\n\",\n",
        "        \"from sklearn.model_selection import train_test_split\\n\",\n",
        "        \"from sklearn.metrics import accuracy_score\\n\",\n",
        "        \"\\n\",\n",
        "        \"nltk.download('punkt')\\n\",\n",
        "        \"nltk.download('stopwords')\\n\",\n",
        "        \"nltk.download('wordnet')\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 0\n",
        "        },\n",
        "        \"id\": \"5sDCewqusLLU\",\n",
        "        \"outputId\": \"bafc7837-4904-4375-c005-f180c3788c63\"\n",
        "      },\n",
        "      \"execution_count\": 2,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"[nltk_data] Downloading package punkt to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Unzipping tokenizers/punkt.zip.\\n\",\n",
        "            \"[nltk_data] Downloading package stopwords to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Unzipping corpora/stopwords.zip.\\n\",\n",
        "            \"[nltk_data] Downloading package wordnet to /root/nltk_data...\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"True\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 2\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"#STEP 3 — Enter a Custom Paragraph\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"KeMj4V2Qsi8l\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"paragraph = \\\"\\\"\\\"\\n\",\n",
        "        \"NLP is an amazing field. It helps computers understand human language.\\n\",\n",
        "        \"We can perform tokenization, remove stopwords, and apply stemming and lemmatization.\\n\",\n",
        "        \"This helps in processing text for Machine Learning.\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"print(\\\"Original Paragraph:\\\\n\\\", paragraph)\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 0\n",
        "        },\n",
        "        \"id\": \"xH7E79yQsl4I\",\n",
        "        \"outputId\": \"2a0accc8-c6ca-41b4-a13b-6c9a00a0a402\"\n",
        "      },\n",
        "      \"execution_count\": 3,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Original Paragraph:\\n\",\n",
        "            \" \\n\",\n",
        "            \"NLP is an amazing field. It helps computers understand human language.\\n\",\n",
        "            \"We can perform tokenization, remove stopwords, and apply stemming and lemmatization.\\n\",\n",
        "            \"This helps in processing text for Machine Learning.\\n\",\n",
        "            \"\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"#STEP 4 — Tokenization\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"Ox_ha_KlstPQ\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"Tokenization is the process of splitting a paragraph into individual words or tokens.\\n\",\n",
        "        \"It helps the computer understand text word-by-word.\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"UWtZeufsuNbn\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"import nltk\\n\",\n",
        "        \"\\n\",\n",
        "        \"nltk.download('punkt')\\n\",\n",
        "        \"nltk.download('punkt_tab')\\n\",\n",
        "        \"nltk.download('stopwords')\\n\",\n",
        "        \"nltk.download('wordnet')\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 0\n",
        "        },\n",
        "        \"id\": \"0FDBTMtstJY6\",\n",
        "        \"outputId\": \"7fb63c08-51b8-4769-8565-0f824b5d638a\"\n",
        "      },\n",
        "      \"execution_count\": 4,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"[nltk_data] Downloading package punkt to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Package punkt is already up-to-date!\\n\",\n",
        "            \"[nltk_data] Downloading package punkt_tab to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\\n\",\n",
        "            \"[nltk_data] Downloading package stopwords to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Package stopwords is already up-to-date!\\n\",\n",
        "            \"[nltk_data] Downloading package wordnet to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Package wordnet is already up-to-date!\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"True\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 4\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"tokens = word_tokenize(paragraph)\\n\",\n",
        "        \"print(\\\"\\\\n--- TOKENIZATION RESULT ---\\\\n\\\")\\n\",\n",
        "        \"print(tokens)\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 0\n",
        "        },\n",
        "        \"id\": \"4neXW5eFsvMo\",\n",
        "        \"outputId\": \"e37458b6-876d-47c3-b6f0-aecd2d26a8d0\"\n",
        "      },\n",
        "      \"execution_count\": 5,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\n\",\n",
        "            \"--- TOKENIZATION RESULT ---\\n\",\n",
        "            \"\\n\",\n",
        "            \"['NLP', 'is', 'an', 'amazing', 'field', '.', 'It', 'helps', 'computers', 'understand', 'human', 'language', '.', 'We', 'can', 'perform', 'tokenization', ',', 'remove', 'stopwords', ',', 'and', 'apply', 'stemming', 'and', 'lemmatization', '.', 'This', 'helps', 'in', 'processing', 'text', 'for', 'Machine', 'Learning', '.']\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"#STEP 5 — Stopword Removal\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"ljbkGrY4tSCX\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"Stopwords are very common words like “the, is, am, are, of, in”.\\n\",\n",
        "        \"They don’t add meaning, so we remove them to keep only important words.\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"0YxOJxRKuTg8\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"stop_words = set(stopwords.words('english'))\\n\",\n",
        "        \"\\n\",\n",
        "        \"filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\n--- AFTER STOPWORD REMOVAL ---\\\\n\\\")\\n\",\n",
        "        \"print(filtered_tokens)\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 0\n",
        "        },\n",
        "        \"id\": \"RrysGzVqtT37\",\n",
        "        \"outputId\": \"0fd04c61-0ff1-4147-b252-67a9fd9c6aa7\"\n",
        "      },\n",
        "      \"execution_count\": 6,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\n\",\n",
        "            \"--- AFTER STOPWORD REMOVAL ---\\n\",\n",
        "            \"\\n\",\n",
        "            \"['NLP', 'amazing', 'field', '.', 'helps', 'computers', 'understand', 'human', 'language', '.', 'perform', 'tokenization', ',', 'remove', 'stopwords', ',', 'apply', 'stemming', 'lemmatization', '.', 'helps', 'processing', 'text', 'Machine', 'Learning', '.']\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"#STEP 6 — Stemming\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"WZLANtgvthYU\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"Stemming reduces words to a basic form by cutting the ends.\\n\",\n",
        "        \"Example:\\n\",\n",
        "        \"\\n\",\n",
        "        \"“playing” → “play”\\n\",\n",
        "        \"\\n\",\n",
        "        \"“studies” → “studi”\\n\",\n",
        "        \"\\n\",\n",
        "        \"It is fast but not always perfect.\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"N89FPZDhuZdA\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"stemmer = PorterStemmer()\\n\",\n",
        "        \"\\n\",\n",
        "        \"stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\n--- STEMMING RESULT ---\\\\n\\\")\\n\",\n",
        "        \"print(stemmed_words)\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 0\n",
        "        },\n",
        "        \"id\": \"lwY2E2v5tmS6\",\n",
        "        \"outputId\": \"3c516241-17b1-4724-f3c5-c1a64c9947ae\"\n",
        "      },\n",
        "      \"execution_count\": 7,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\n\",\n",
        "            \"--- STEMMING RESULT ---\\n\",\n",
        "            \"\\n\",\n",
        "            \"['nlp', 'amaz', 'field', '.', 'help', 'comput', 'understand', 'human', 'languag', '.', 'perform', 'token', ',', 'remov', 'stopword', ',', 'appli', 'stem', 'lemmat', '.', 'help', 'process', 'text', 'machin', 'learn', '.']\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"#STEP 7 — Lemmatization\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"BLO1p4DZtskw\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"Lemmatization converts a word to its proper dictionary base form.\\n\",\n",
        "        \"Example:\\n\",\n",
        "        \"\\n\",\n",
        "        \"“better” → “good”\\n\",\n",
        "        \"\\n\",\n",
        "        \"“studies” → “study”\\n\",\n",
        "        \"\\n\",\n",
        "        \"It is more accurate than stemming because it uses vocabulary + grammar rules.\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"Hlt5H9ZTue4F\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"lemmatizer = WordNetLemmatizer()\\n\",\n",
        "        \"\\n\",\n",
        "        \"lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\n--- LEMMATIZATION RESULT ---\\\\n\\\")\\n\",\n",
        "        \"print(lemmatized_words)\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 0\n",
        "        },\n",
        "        \"id\": \"BcOkOyMGtxW7\",\n",
        "        \"outputId\": \"9ac74b37-95ad-4efa-efe6-a498e9a2ef21\"\n",
        "      },\n",
        "      \"execution_count\": 8,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\n\",\n",
        "            \"--- LEMMATIZATION RESULT ---\\n\",\n",
        "            \"\\n\",\n",
        "            \"['NLP', 'amazing', 'field', '.', 'help', 'computer', 'understand', 'human', 'language', '.', 'perform', 'tokenization', ',', 'remove', 'stopwords', ',', 'apply', 'stemming', 'lemmatization', '.', 'help', 'processing', 'text', 'Machine', 'Learning', '.']\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    }
  ]
}